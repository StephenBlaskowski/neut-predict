{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Alphabet import generic_protein\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in neut data\n",
    "\n",
    "neut_file_path = '../data/2G12_IC50_IC80.txt'\n",
    "\n",
    "neuts = pd.read_table(neut_file_path, header=0)\n",
    "neuts.rename(columns={'Virus name':'name', \n",
    "              'Subtype':'subtype',\n",
    "              '2G12: IC50 geometric mean':'IC50',\n",
    "              '2G12: IC80 geometric mean':'IC80'}, inplace=True)\n",
    "# neuts.set_index('name', inplace=True)\n",
    "neuts.drop(['Tier', 'Country', 'Accession', 'Alias', 'Seq data', \n",
    "            ' 2G12: IC50 by study', ' 2G12: IC80 by study', 'Unnamed: 11'], \n",
    "            axis=1, inplace=True)\n",
    "neuts = neuts[neuts.name != 'Geometric mean of detected']\n",
    "neuts = neuts[neuts.name != 'Geometric mean of all(undetected set to 100)'] \n",
    "neuts = neuts[neuts.name != '% detected (detected/total)'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in sequence data\n",
    "\n",
    "virus_name = []\n",
    "virus_seq = []\n",
    "passed_seqs = []\n",
    "\n",
    "fasta_file_path = '../data/2G12 virus aa align.fasta'\n",
    "\n",
    "for seq_record in SeqIO.parse(fasta_file_path, 'fasta', \n",
    "                              alphabet=generic_protein):\n",
    "    try:\n",
    "        virus_name.append(seq_record.id.split('.')[2])\n",
    "        virus_seq.append(seq_record.seq)\n",
    "    except:\n",
    "        passed_seqs.append(seq_record)\n",
    "\n",
    "HXB2 = passed_seqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert sequence data to DataFrame\n",
    "\n",
    "seq_dict = {'sequence' : pd.Series(virus_seq, index=virus_name, \n",
    "                                   dtype='object')}\n",
    "seq_df = pd.DataFrame(seq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge neuts and seq_df\n",
    "\n",
    "neutdf = pd.merge(neuts, seq_df, how='inner', left_on='name', \n",
    "                    right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define neut categories\n",
    "\n",
    "def binarize_IC50(row):\n",
    "    if '>' in row.IC50:\n",
    "        return 0\n",
    "    else:\n",
    "        value = float(row.IC50)\n",
    "        return 0 if value > 50 else 1\n",
    "\n",
    "neutdf['is_neutralized'] = neutdf.apply(binarize_IC50, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>subtype</th>\n",
       "      <th>IC50</th>\n",
       "      <th>IC80</th>\n",
       "      <th>sequence</th>\n",
       "      <th>is_neutralized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013095_2_11</td>\n",
       "      <td>C</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>(M, R, V, K, G, I, L, R, N, Y, -, Q, Q, W, W, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001428_2_42</td>\n",
       "      <td>C</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>(M, R, V, R, G, I, L, R, N, Y, -, Q, Q, W, W, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0041_V3_C18</td>\n",
       "      <td>C</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>-</td>\n",
       "      <td>(M, R, V, R, G, I, L, R, N, W, -, Q, L, W, W, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0077_V1_C16</td>\n",
       "      <td>C</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>(M, R, V, M, G, S, M, R, N, C, -, Q, R, W, W, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00836_2_5</td>\n",
       "      <td>C</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>(M, R, V, R, G, I, R, R, N, Y, -, Q, H, W, W, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name subtype    IC50    IC80  \\\n",
       "0  0013095_2_11       C  UD:>50  UD:>50   \n",
       "1   001428_2_42       C  UD:>50  UD:>50   \n",
       "2   0041_V3_C18       C  UD:>50       -   \n",
       "3   0077_V1_C16       C  UD:>50  UD:>50   \n",
       "4     00836_2_5       C  UD:>50  UD:>50   \n",
       "\n",
       "                                            sequence  is_neutralized  \n",
       "0  (M, R, V, K, G, I, L, R, N, Y, -, Q, Q, W, W, ...               0  \n",
       "1  (M, R, V, R, G, I, L, R, N, Y, -, Q, Q, W, W, ...               0  \n",
       "2  (M, R, V, R, G, I, L, R, N, W, -, Q, L, W, W, ...               0  \n",
       "3  (M, R, V, M, G, S, M, R, N, C, -, Q, R, W, W, ...               0  \n",
       "4  (M, R, V, R, G, I, R, R, N, Y, -, Q, H, W, W, ...               0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "    Tokenize sequences w/ position value and amino acid identity\n",
    "    Tokenize PNGS sites with a regex\n",
    "    Vectorize tokens and create dataframe of dummy variables\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to tokenize sequence\n",
    "# input = sequence object, output = dictionary where index is position and\n",
    "# token is amino acid identity at that position\n",
    "\n",
    "amino_acids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', \n",
    "               'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "\n",
    "def sequence_tokenizer(seq):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    seq_list = list(str(seq).strip('*'))\n",
    "    working_peptide = list(enumerate(seq_list, start=1))\n",
    "    peptide_dict = {}\n",
    "    for index, amino in working_peptide:\n",
    "        if amino in amino_acids:\n",
    "            peptide_dict.update({index : amino})\n",
    "        else: \n",
    "            pass\n",
    "    return peptide_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to tokenize potential N-linked glycosylation sites \n",
    "# (PNGS) in sequence\n",
    "# input = sequence object, output = dictionary where index is position\n",
    "# and token = 'PNGS'\n",
    "\n",
    "def PNGS_tokenizer(seq):\n",
    "    seq_string = str(seq).strip('*')\n",
    "    PNGS_dict = {m.start(0)+1 : 'PNGS' \n",
    "                for m in re.finditer(r\"N[^P][ST]\", seq_string)}\n",
    "    return PNGS_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define feature extraction function where input = seq object and \n",
    "# output = one dictionary of all features\n",
    "\n",
    "def get_features(seq, use_positions=True, use_PNGS=True):\n",
    "    features = {}\n",
    "    if use_positions:\n",
    "        sequence_features = sequence_tokenizer(seq)\n",
    "        features.update(sequence_features)\n",
    "    if use_PNGS:\n",
    "        PNGS_features = PNGS_tokenizer(seq)\n",
    "        features.update(PNGS_features)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map get_features function to sequence column of neutdf\n",
    "\n",
    "neutdf['features_dict'] = neutdf.sequence.map(get_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>subtype</th>\n",
       "      <th>IC50</th>\n",
       "      <th>IC80</th>\n",
       "      <th>sequence</th>\n",
       "      <th>is_neutralized</th>\n",
       "      <th>features_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013095_2_11</td>\n",
       "      <td>C</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>(M, R, V, K, G, I, L, R, N, Y, -, Q, Q, W, W, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{1: u'M', 2: u'R', 3: u'V', 4: u'K', 5: u'G', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001428_2_42</td>\n",
       "      <td>C</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>(M, R, V, R, G, I, L, R, N, Y, -, Q, Q, W, W, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{1: u'M', 2: u'R', 3: u'V', 4: u'R', 5: u'G', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0041_V3_C18</td>\n",
       "      <td>C</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>-</td>\n",
       "      <td>(M, R, V, R, G, I, L, R, N, W, -, Q, L, W, W, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{1: u'M', 2: u'R', 3: u'V', 4: u'R', 5: u'G', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0077_V1_C16</td>\n",
       "      <td>C</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>(M, R, V, M, G, S, M, R, N, C, -, Q, R, W, W, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{1: u'M', 2: u'R', 3: u'V', 4: u'M', 5: u'G', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00836_2_5</td>\n",
       "      <td>C</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>UD:&gt;50</td>\n",
       "      <td>(M, R, V, R, G, I, R, R, N, Y, -, Q, H, W, W, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{1: u'M', 2: u'R', 3: u'V', 4: u'R', 5: u'G', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name subtype    IC50    IC80  \\\n",
       "0  0013095_2_11       C  UD:>50  UD:>50   \n",
       "1   001428_2_42       C  UD:>50  UD:>50   \n",
       "2   0041_V3_C18       C  UD:>50       -   \n",
       "3   0077_V1_C16       C  UD:>50  UD:>50   \n",
       "4     00836_2_5       C  UD:>50  UD:>50   \n",
       "\n",
       "                                            sequence  is_neutralized  \\\n",
       "0  (M, R, V, K, G, I, L, R, N, Y, -, Q, Q, W, W, ...               0   \n",
       "1  (M, R, V, R, G, I, L, R, N, Y, -, Q, Q, W, W, ...               0   \n",
       "2  (M, R, V, R, G, I, L, R, N, W, -, Q, L, W, W, ...               0   \n",
       "3  (M, R, V, M, G, S, M, R, N, C, -, Q, R, W, W, ...               0   \n",
       "4  (M, R, V, R, G, I, R, R, N, Y, -, Q, H, W, W, ...               0   \n",
       "\n",
       "                                       features_dict  \n",
       "0  {1: u'M', 2: u'R', 3: u'V', 4: u'K', 5: u'G', ...  \n",
       "1  {1: u'M', 2: u'R', 3: u'V', 4: u'R', 5: u'G', ...  \n",
       "2  {1: u'M', 2: u'R', 3: u'V', 4: u'R', 5: u'G', ...  \n",
       "3  {1: u'M', 2: u'R', 3: u'V', 4: u'M', 5: u'G', ...  \n",
       "4  {1: u'M', 2: u'R', 3: u'V', 4: u'R', 5: u'G', ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100=A</th>\n",
       "      <th>100=D</th>\n",
       "      <th>100=K</th>\n",
       "      <th>100=N</th>\n",
       "      <th>100=R</th>\n",
       "      <th>100=S</th>\n",
       "      <th>100=T</th>\n",
       "      <th>101=P</th>\n",
       "      <th>102=H</th>\n",
       "      <th>102=I</th>\n",
       "      <th>...</th>\n",
       "      <th>99=P</th>\n",
       "      <th>9=D</th>\n",
       "      <th>9=G</th>\n",
       "      <th>9=H</th>\n",
       "      <th>9=I</th>\n",
       "      <th>9=K</th>\n",
       "      <th>9=N</th>\n",
       "      <th>9=R</th>\n",
       "      <th>9=S</th>\n",
       "      <th>9=T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   100=A  100=D  100=K  100=N  100=R  100=S  100=T  101=P  102=H  102=I ...   \\\n",
       "0      0      0      0      1      0      0      0      1      0      0 ...    \n",
       "1      0      0      0      1      0      0      0      1      0      0 ...    \n",
       "2      0      0      0      1      0      0      0      1      0      0 ...    \n",
       "3      0      1      0      0      0      0      0      1      0      0 ...    \n",
       "4      0      0      0      1      0      0      0      1      0      0 ...    \n",
       "\n",
       "   99=P  9=D  9=G  9=H  9=I  9=K  9=N  9=R  9=S  9=T  \n",
       "0     1    0    0    0    0    0    1    0    0    0  \n",
       "1     1    0    0    0    0    0    1    0    0    0  \n",
       "2     1    0    0    0    0    0    1    0    0    0  \n",
       "3     1    0    0    0    0    0    1    0    0    0  \n",
       "4     1    0    0    0    0    0    1    0    0    0  \n",
       "\n",
       "[5 rows x 6226 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize data and build feature df\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "d_vect = DictVectorizer()\n",
    "\n",
    "list_features = list(neutdf.features_dict)\n",
    "sparse_features = d_vect.fit_transform(list_features)\n",
    "name_features = d_vect.get_feature_names()\n",
    "\n",
    "features_df = pd.DataFrame(sparse_features.toarray(), columns=name_features)\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up position in HXB2 for it's corresponding coordinate in the MSA\n",
    "\n",
    "reference = sequence_tokenizer(HXB2.seq)\n",
    "decoder = dict(enumerate(reference, start=1))\n",
    "decoder[295]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['363=D', '363=E', '363=H', '363=I', '363=K', '363=L', '363=M', '363=N', '363=PNGS', '363=R', '363=S', '363=T', '363=V', '363=Y']\n"
     ]
    }
   ],
   "source": [
    "# Examine features at positions 665 & 667 (MSA: 789 & 791)\n",
    "\n",
    "epitope_features = [col for col in features_df.columns if '363' in col]\n",
    "print epitope_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "    Trim down feature outliers (highly conserved sequences & single variants)\n",
    "    Other feature selection approaches (mRMR, incorporated methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_counts = np.sum(features_df, axis=0)/features_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10a407050>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEKCAYAAADTgGjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a3ef7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "% matplotlib inline\n",
    "\n",
    "feature_counts.plot.hist(title='Feature Frequencies', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to drop features that are shared by less than X% of sequences and/or more\n",
    "# than 1-X% of sequences\n",
    "\n",
    "def trim_feature_extremes(dataframe, percent_to_trim):\n",
    "    total_rows = dataframe.shape[0]\n",
    "    upper_threshold = (1 - percent_to_trim) * total_rows\n",
    "    lower_threshold = percent_to_trim * total_rows\n",
    "    column_filter_list = list((dataframe.sum(axis=0) >= lower_threshold) &\n",
    "                                (dataframe.sum(axis=0) < upper_threshold)) \n",
    "                                #True = keep, False = drop\n",
    "    column_filter_dict = zip(list(dataframe.columns), column_filter_list)\n",
    "    columns_to_keep = [column for column, keepornot in column_filter_dict \n",
    "                        if keepornot == True]\n",
    "    output_df = dataframe[columns_to_keep]\n",
    "    return output_df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 1333)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmed_features_df = trim_feature_extremes(features_df, 0.05)\n",
    "\n",
    "trimmed_features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Decision Tree Classifier\n",
    "\n",
    "    Use for feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define X & y as whole feature set without trimming features\n",
    "\n",
    "X = features_df\n",
    "y = neutdf.is_neutralized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77917852062588899, 0.85249525841631102, 0.88206334324755375, 0.8525327061511272, 0.84449868528815897, 0.86377106771843604, 0.8130840768998665, 0.83418358549937499, 0.81356712573817835, 0.8070576856761067, 0.78745851114272158, 0.80571145307987402, 0.80796855467908091, 0.79134876503297558, 0.79374865295917929, 0.79198887883098412, 0.81210558644769171, 0.83737607224449329, 0.808341954394586, 0.81702390189232299, 0.79153304021725079, 0.811505883874305, 0.8138357256778308, 0.82914511401353508, 0.82152840639682745, 0.815933337643864, 0.82798881417302472, 0.81244288546920118, 0.80451851372904015, 0.80700622871675498, 0.81585628690891843, 0.81292889779731881, 0.82148691753954917, 0.82258340876761937, 0.8110090952196215, 0.80486173973016073, 0.81860640544851082, 0.78623432044484687, 0.81601038837880946, 0.82626891245312295, 0.81423876029139186, 0.81458198629251266, 0.8187486529591792, 0.81030270701323348, 0.81218102073365228, 0.8077481788008104, 0.79934372171214274, 0.8181150049571102, 0.79915405836458464, 0.80917765851976375, 0.82097127031337558, 0.8209243932928143, 0.80613604034656672, 0.8205811672916935, 0.82269602138023201, 0.77538740894004055, 0.81375867494288534, 0.81106028277080922, 0.81026714513556608, 0.82021261692314318, 0.82469233587654645, 0.80294193715246354, 0.82291531962584608, 0.82633572567783076, 0.81665104099314623, 0.81446937367990002, 0.80576317944738984, 0.77851038837880926, 0.83647032199663784, 0.79964114832535882, 0.78909651278072324, 0.80467261519893096, 0.82355597224018273, 0.82724147592568653, 0.79641579378421479, 0.79742391913444544, 0.81852342773395415, 0.82107256778309412, 0.82183607052028107, 0.80587579206000259, 0.80722121643174261, 0.81957896892107418, 0.81289872408293462, 0.82037210655631709, 0.82209631880684508, 0.80969869390922022, 0.81458198629251266, 0.78969459890512528, 0.81736173973016069, 0.80860812966076112, 0.81698295185137282, 0.81838118022328543, 0.80860812966076134, 0.80294786413207464, 0.81304689857321433, 0.78005140307771892, 0.80466668821931986, 0.79495182982025081, 0.80880910815121343, 0.80167356351566865]\n"
     ]
    }
   ],
   "source": [
    "# calculate best depth using roc_auc score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_depth_range = range(1, 101)\n",
    "\n",
    "roc_auc_scores = []\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "for depth in max_depth_range:\n",
    "    treeclass = DecisionTreeClassifier(max_depth=depth)\n",
    "    score = cross_val_score(treeclass, X, y, scoring='roc_auc', cv=10)\n",
    "    roc_auc_scores.append(np.mean(score))\n",
    "    \n",
    "print roc_auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGDCAYAAAAmkGrdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlM5/A0Xb6LxcVn+gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a36eed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graph roc_auc_scores vs max depth\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(max_depth_range, roc_auc_scores)\n",
    "plt.xlabel('max depth')\n",
    "plt.ylabel('roc auc score')\n",
    "\n",
    "plt.rcdefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88206334324755375, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(roc_auc_scores, max_depth_range), reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit tree using max depth of 10\n",
    "\n",
    "treeclass = DecisionTreeClassifier(max_depth=10)\n",
    "treeclass.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>363=PNGS</td>\n",
       "      <td>0.236450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>408=N</td>\n",
       "      <td>0.183398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>479=PNGS</td>\n",
       "      <td>0.127432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078</th>\n",
       "      <td>7=L</td>\n",
       "      <td>0.053283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>480=S</td>\n",
       "      <td>0.038936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>872=V</td>\n",
       "      <td>0.032765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>429=Y</td>\n",
       "      <td>0.031546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>406=H</td>\n",
       "      <td>0.031275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>160=A</td>\n",
       "      <td>0.025463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>430=W</td>\n",
       "      <td>0.021455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "2083  363=PNGS    0.236450\n",
       "2435     408=N    0.183398\n",
       "3047  479=PNGS    0.127432\n",
       "5078       7=L    0.053283\n",
       "3070     480=S    0.038936\n",
       "5468     872=V    0.032765\n",
       "2671     429=Y    0.031546\n",
       "2422     406=H    0.031275\n",
       "404      160=A    0.025463\n",
       "2685     430=W    0.021455"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get feature importances\n",
    "\n",
    "feat_import = pd.DataFrame({'feature': features_df.columns, 'importance': treeclass.feature_importances_})\n",
    "feat_import.sort_values('importance', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up position in HXB2 for it's corresponding coordinate in the MSA\n",
    "\n",
    "reference = sequence_tokenizer(HXB2.seq)\n",
    "decoder = dict(enumerate(reference, start=1))\n",
    "decoder[466]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at other feature importances at same sites\n",
    "\n",
    "features_363 = [feat for feat in feat_import.feature if '363' in feat]\n",
    "features_408 = [feat for feat in feat_import.feature if '408' in feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>feature</th>\n",
       "      <th>363=D</th>\n",
       "      <th>363=E</th>\n",
       "      <th>363=H</th>\n",
       "      <th>363=I</th>\n",
       "      <th>363=K</th>\n",
       "      <th>363=L</th>\n",
       "      <th>363=M</th>\n",
       "      <th>363=N</th>\n",
       "      <th>363=PNGS</th>\n",
       "      <th>363=R</th>\n",
       "      <th>363=S</th>\n",
       "      <th>363=T</th>\n",
       "      <th>363=V</th>\n",
       "      <th>363=Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>importance</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "feature     363=D  363=E  363=H  363=I  363=K  363=L  363=M  363=N  363=PNGS  \\\n",
       "importance      0      0      0      0      0      0      0      0   0.23645   \n",
       "\n",
       "feature     363=R  363=S  363=T  363=V  363=Y  \n",
       "importance      0      0      0      0      0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_import.set_index('feature', inplace=True)\n",
    "import_feat = feat_import.transpose()\n",
    "import_feat[features_363]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>feature</th>\n",
       "      <th>408=D</th>\n",
       "      <th>408=E</th>\n",
       "      <th>408=H</th>\n",
       "      <th>408=I</th>\n",
       "      <th>408=K</th>\n",
       "      <th>408=L</th>\n",
       "      <th>408=N</th>\n",
       "      <th>408=PNGS</th>\n",
       "      <th>408=R</th>\n",
       "      <th>408=S</th>\n",
       "      <th>408=T</th>\n",
       "      <th>408=V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>importance</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "feature     408=D  408=E  408=H  408=I  408=K  408=L     408=N  408=PNGS  \\\n",
       "importance      0      0      0      0      0      0  0.183398         0   \n",
       "\n",
       "feature     408=R  408=S  408=T  408=V  \n",
       "importance      0      0      0      0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_feat[features_408]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Random Forest\n",
    "    \n",
    "    Use randomized grid search CV for n_estimators, max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import random forest classifier & define X & y using trimmed dataframe\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfclass = RandomForestClassifier()\n",
    "\n",
    "X = trimmed_features_df\n",
    "y = neutdf.is_neutralized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "estimators_range = range(1, 1502, 10)\n",
    "feature_range = range(1, 502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params={}, iid=True, n_iter=50, n_jobs=1,\n",
       "          param_distributions={'max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,...41, 1351, 1361, 1371, 1381, 1391, 1401, 1411, 1421, 1431, 1441, 1451, 1461, 1471, 1481, 1491, 1501]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist = dict(n_estimators=estimators_range, max_features=feature_range)\n",
    "rand = RandomizedSearchCV(rfclass, param_dist, n_iter=50, scoring='roc_auc', cv=5)\n",
    "rand.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>mean_validation_score</th>\n",
       "      <th>cv_validation_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>{u'n_estimators': 291, u'max_features': 411}</td>\n",
       "      <td>0.912278</td>\n",
       "      <td>[0.922222222222, 0.89161036036, 0.882601351351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>{u'n_estimators': 881, u'max_features': 411}</td>\n",
       "      <td>0.911934</td>\n",
       "      <td>[0.913611111111, 0.902308558559, 0.88541666666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{u'n_estimators': 991, u'max_features': 427}</td>\n",
       "      <td>0.911659</td>\n",
       "      <td>[0.908055555556, 0.898367117117, 0.88569819819...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{u'n_estimators': 701, u'max_features': 501}</td>\n",
       "      <td>0.911601</td>\n",
       "      <td>[0.904722222222, 0.902027027027, 0.88400900900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{u'n_estimators': 331, u'max_features': 488}</td>\n",
       "      <td>0.911422</td>\n",
       "      <td>[0.909444444444, 0.891328828829, 0.89020270270...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{u'n_estimators': 1111, u'max_features': 461}</td>\n",
       "      <td>0.910308</td>\n",
       "      <td>[0.905833333333, 0.901463963964, 0.88654279279...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>{u'n_estimators': 941, u'max_features': 491}</td>\n",
       "      <td>0.910283</td>\n",
       "      <td>[0.911944444444, 0.89527027027, 0.880349099099...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{u'n_estimators': 821, u'max_features': 488}</td>\n",
       "      <td>0.910146</td>\n",
       "      <td>[0.900277777778, 0.890484234234, 0.89245495495...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{u'n_estimators': 1201, u'max_features': 440}</td>\n",
       "      <td>0.909304</td>\n",
       "      <td>[0.905833333333, 0.900337837838, 0.88119369369...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{u'n_estimators': 1341, u'max_features': 435}</td>\n",
       "      <td>0.908930</td>\n",
       "      <td>[0.9025, 0.893018018018, 0.88597972973, 0.9752...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>{u'n_estimators': 531, u'max_features': 425}</td>\n",
       "      <td>0.908817</td>\n",
       "      <td>[0.906111111111, 0.897240990991, 0.88034909909...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{u'n_estimators': 271, u'max_features': 468}</td>\n",
       "      <td>0.907421</td>\n",
       "      <td>[0.904722222222, 0.886261261261, 0.89273648648...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{u'n_estimators': 741, u'max_features': 350}</td>\n",
       "      <td>0.907012</td>\n",
       "      <td>[0.9, 0.896114864865, 0.881756756757, 0.970157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>{u'n_estimators': 1051, u'max_features': 422}</td>\n",
       "      <td>0.906826</td>\n",
       "      <td>[0.901111111111, 0.89527027027, 0.877252252252...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{u'n_estimators': 241, u'max_features': 432}</td>\n",
       "      <td>0.906543</td>\n",
       "      <td>[0.894444444444, 0.892736486486, 0.88879504504...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{u'n_estimators': 1021, u'max_features': 365}</td>\n",
       "      <td>0.905161</td>\n",
       "      <td>[0.899722222222, 0.896396396396, 0.87865990991...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{u'n_estimators': 131, u'max_features': 480}</td>\n",
       "      <td>0.904795</td>\n",
       "      <td>[0.896388888889, 0.902027027027, 0.87528153153...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{u'n_estimators': 1411, u'max_features': 389}</td>\n",
       "      <td>0.904766</td>\n",
       "      <td>[0.897222222222, 0.896396396396, 0.87781531531...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{u'n_estimators': 81, u'max_features': 435}</td>\n",
       "      <td>0.904305</td>\n",
       "      <td>[0.888611111111, 0.905123873874, 0.87837837837...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{u'n_estimators': 1111, u'max_features': 310}</td>\n",
       "      <td>0.904267</td>\n",
       "      <td>[0.898611111111, 0.897804054054, 0.88288288288...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>{u'n_estimators': 471, u'max_features': 288}</td>\n",
       "      <td>0.904264</td>\n",
       "      <td>[0.8925, 0.904842342342, 0.872466216216, 0.972...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{u'n_estimators': 351, u'max_features': 423}</td>\n",
       "      <td>0.903588</td>\n",
       "      <td>[0.883611111111, 0.898367117117, 0.87528153153...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{u'n_estimators': 1411, u'max_features': 353}</td>\n",
       "      <td>0.903205</td>\n",
       "      <td>[0.893333333333, 0.894988738739, 0.87359234234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{u'n_estimators': 731, u'max_features': 291}</td>\n",
       "      <td>0.902881</td>\n",
       "      <td>[0.900555555556, 0.905405405405, 0.87105855855...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{u'n_estimators': 871, u'max_features': 264}</td>\n",
       "      <td>0.902687</td>\n",
       "      <td>[0.893333333333, 0.896959459459, 0.875, 0.9690...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{u'n_estimators': 1421, u'max_features': 303}</td>\n",
       "      <td>0.902392</td>\n",
       "      <td>[0.900555555556, 0.897240990991, 0.86711711711...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{u'n_estimators': 1071, u'max_features': 294}</td>\n",
       "      <td>0.901479</td>\n",
       "      <td>[0.899444444444, 0.891047297297, 0.86965090090...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{u'n_estimators': 1431, u'max_features': 284}</td>\n",
       "      <td>0.900719</td>\n",
       "      <td>[0.897222222222, 0.890765765766, 0.87162162162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{u'n_estimators': 1221, u'max_features': 297}</td>\n",
       "      <td>0.900268</td>\n",
       "      <td>[0.8925, 0.893581081081, 0.875844594595, 0.969...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>{u'n_estimators': 311, u'max_features': 304}</td>\n",
       "      <td>0.898512</td>\n",
       "      <td>[0.904166666667, 0.901182432432, 0.86486486486...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{u'n_estimators': 241, u'max_features': 222}</td>\n",
       "      <td>0.895028</td>\n",
       "      <td>[0.879722222222, 0.894425675676, 0.86655405405...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{u'n_estimators': 201, u'max_features': 285}</td>\n",
       "      <td>0.894915</td>\n",
       "      <td>[0.882777777778, 0.897804054054, 0.86120495495...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{u'n_estimators': 1321, u'max_features': 186}</td>\n",
       "      <td>0.891807</td>\n",
       "      <td>[0.883888888889, 0.899774774775, 0.86036036036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{u'n_estimators': 291, u'max_features': 188}</td>\n",
       "      <td>0.890781</td>\n",
       "      <td>[0.875, 0.894707207207, 0.857545045045, 0.9625...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{u'n_estimators': 1081, u'max_features': 175}</td>\n",
       "      <td>0.890738</td>\n",
       "      <td>[0.880833333333, 0.892454954955, 0.85726351351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{u'n_estimators': 261, u'max_features': 208}</td>\n",
       "      <td>0.889761</td>\n",
       "      <td>[0.887777777778, 0.891047297297, 0.86373873873...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{u'n_estimators': 631, u'max_features': 197}</td>\n",
       "      <td>0.888800</td>\n",
       "      <td>[0.878611111111, 0.893581081081, 0.86007882882...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{u'n_estimators': 341, u'max_features': 125}</td>\n",
       "      <td>0.884732</td>\n",
       "      <td>[0.873611111111, 0.899211711712, 0.85304054054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{u'n_estimators': 1201, u'max_features': 141}</td>\n",
       "      <td>0.883608</td>\n",
       "      <td>[0.869166666667, 0.890202702703, 0.85472972973...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{u'n_estimators': 681, u'max_features': 133}</td>\n",
       "      <td>0.879056</td>\n",
       "      <td>[0.861944444444, 0.888513513514, 0.84177927927...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>{u'n_estimators': 101, u'max_features': 182}</td>\n",
       "      <td>0.878055</td>\n",
       "      <td>[0.860555555556, 0.888513513514, 0.84712837837...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{u'n_estimators': 1291, u'max_features': 67}</td>\n",
       "      <td>0.864508</td>\n",
       "      <td>[0.829166666667, 0.884009009009, 0.84177927927...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{u'n_estimators': 861, u'max_features': 47}</td>\n",
       "      <td>0.856758</td>\n",
       "      <td>[0.815555555556, 0.885416666667, 0.82573198198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{u'n_estimators': 791, u'max_features': 28}</td>\n",
       "      <td>0.838136</td>\n",
       "      <td>[0.761944444444, 0.868243243243, 0.81587837837...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{u'n_estimators': 311, u'max_features': 32}</td>\n",
       "      <td>0.837876</td>\n",
       "      <td>[0.786944444444, 0.858952702703, 0.82291666666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>{u'n_estimators': 1411, u'max_features': 22}</td>\n",
       "      <td>0.830143</td>\n",
       "      <td>[0.756666666667, 0.868243243243, 0.81081081081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{u'n_estimators': 21, u'max_features': 102}</td>\n",
       "      <td>0.814541</td>\n",
       "      <td>[0.704444444444, 0.882601351351, 0.83727477477...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{u'n_estimators': 11, u'max_features': 125}</td>\n",
       "      <td>0.809656</td>\n",
       "      <td>[0.743333333333, 0.786317567568, 0.79729729729...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{u'n_estimators': 1041, u'max_features': 3}</td>\n",
       "      <td>0.806192</td>\n",
       "      <td>[0.698611111111, 0.862612612613, 0.78125, 0.91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{u'n_estimators': 91, u'max_features': 10}</td>\n",
       "      <td>0.790627</td>\n",
       "      <td>[0.714444444444, 0.817004504505, 0.78941441441...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       parameters  mean_validation_score  \\\n",
       "48   {u'n_estimators': 291, u'max_features': 411}               0.912278   \n",
       "40   {u'n_estimators': 881, u'max_features': 411}               0.911934   \n",
       "14   {u'n_estimators': 991, u'max_features': 427}               0.911659   \n",
       "15   {u'n_estimators': 701, u'max_features': 501}               0.911601   \n",
       "17   {u'n_estimators': 331, u'max_features': 488}               0.911422   \n",
       "20  {u'n_estimators': 1111, u'max_features': 461}               0.910308   \n",
       "41   {u'n_estimators': 941, u'max_features': 491}               0.910283   \n",
       "47   {u'n_estimators': 821, u'max_features': 488}               0.910146   \n",
       "26  {u'n_estimators': 1201, u'max_features': 440}               0.909304   \n",
       "25  {u'n_estimators': 1341, u'max_features': 435}               0.908930   \n",
       "49   {u'n_estimators': 531, u'max_features': 425}               0.908817   \n",
       "29   {u'n_estimators': 271, u'max_features': 468}               0.907421   \n",
       "23   {u'n_estimators': 741, u'max_features': 350}               0.907012   \n",
       "39  {u'n_estimators': 1051, u'max_features': 422}               0.906826   \n",
       "22   {u'n_estimators': 241, u'max_features': 432}               0.906543   \n",
       "8   {u'n_estimators': 1021, u'max_features': 365}               0.905161   \n",
       "34   {u'n_estimators': 131, u'max_features': 480}               0.904795   \n",
       "28  {u'n_estimators': 1411, u'max_features': 389}               0.904766   \n",
       "9     {u'n_estimators': 81, u'max_features': 435}               0.904305   \n",
       "12  {u'n_estimators': 1111, u'max_features': 310}               0.904267   \n",
       "45   {u'n_estimators': 471, u'max_features': 288}               0.904264   \n",
       "30   {u'n_estimators': 351, u'max_features': 423}               0.903588   \n",
       "7   {u'n_estimators': 1411, u'max_features': 353}               0.903205   \n",
       "32   {u'n_estimators': 731, u'max_features': 291}               0.902881   \n",
       "38   {u'n_estimators': 871, u'max_features': 264}               0.902687   \n",
       "18  {u'n_estimators': 1421, u'max_features': 303}               0.902392   \n",
       "6   {u'n_estimators': 1071, u'max_features': 294}               0.901479   \n",
       "16  {u'n_estimators': 1431, u'max_features': 284}               0.900719   \n",
       "35  {u'n_estimators': 1221, u'max_features': 297}               0.900268   \n",
       "46   {u'n_estimators': 311, u'max_features': 304}               0.898512   \n",
       "11   {u'n_estimators': 241, u'max_features': 222}               0.895028   \n",
       "3    {u'n_estimators': 201, u'max_features': 285}               0.894915   \n",
       "2   {u'n_estimators': 1321, u'max_features': 186}               0.891807   \n",
       "5    {u'n_estimators': 291, u'max_features': 188}               0.890781   \n",
       "4   {u'n_estimators': 1081, u'max_features': 175}               0.890738   \n",
       "13   {u'n_estimators': 261, u'max_features': 208}               0.889761   \n",
       "0    {u'n_estimators': 631, u'max_features': 197}               0.888800   \n",
       "31   {u'n_estimators': 341, u'max_features': 125}               0.884732   \n",
       "44  {u'n_estimators': 1201, u'max_features': 141}               0.883608   \n",
       "27   {u'n_estimators': 681, u'max_features': 133}               0.879056   \n",
       "42   {u'n_estimators': 101, u'max_features': 182}               0.878055   \n",
       "1    {u'n_estimators': 1291, u'max_features': 67}               0.864508   \n",
       "19    {u'n_estimators': 861, u'max_features': 47}               0.856758   \n",
       "33    {u'n_estimators': 791, u'max_features': 28}               0.838136   \n",
       "10    {u'n_estimators': 311, u'max_features': 32}               0.837876   \n",
       "37   {u'n_estimators': 1411, u'max_features': 22}               0.830143   \n",
       "36    {u'n_estimators': 21, u'max_features': 102}               0.814541   \n",
       "43    {u'n_estimators': 11, u'max_features': 125}               0.809656   \n",
       "24    {u'n_estimators': 1041, u'max_features': 3}               0.806192   \n",
       "21     {u'n_estimators': 91, u'max_features': 10}               0.790627   \n",
       "\n",
       "                                 cv_validation_scores  \n",
       "48  [0.922222222222, 0.89161036036, 0.882601351351...  \n",
       "40  [0.913611111111, 0.902308558559, 0.88541666666...  \n",
       "14  [0.908055555556, 0.898367117117, 0.88569819819...  \n",
       "15  [0.904722222222, 0.902027027027, 0.88400900900...  \n",
       "17  [0.909444444444, 0.891328828829, 0.89020270270...  \n",
       "20  [0.905833333333, 0.901463963964, 0.88654279279...  \n",
       "41  [0.911944444444, 0.89527027027, 0.880349099099...  \n",
       "47  [0.900277777778, 0.890484234234, 0.89245495495...  \n",
       "26  [0.905833333333, 0.900337837838, 0.88119369369...  \n",
       "25  [0.9025, 0.893018018018, 0.88597972973, 0.9752...  \n",
       "49  [0.906111111111, 0.897240990991, 0.88034909909...  \n",
       "29  [0.904722222222, 0.886261261261, 0.89273648648...  \n",
       "23  [0.9, 0.896114864865, 0.881756756757, 0.970157...  \n",
       "39  [0.901111111111, 0.89527027027, 0.877252252252...  \n",
       "22  [0.894444444444, 0.892736486486, 0.88879504504...  \n",
       "8   [0.899722222222, 0.896396396396, 0.87865990991...  \n",
       "34  [0.896388888889, 0.902027027027, 0.87528153153...  \n",
       "28  [0.897222222222, 0.896396396396, 0.87781531531...  \n",
       "9   [0.888611111111, 0.905123873874, 0.87837837837...  \n",
       "12  [0.898611111111, 0.897804054054, 0.88288288288...  \n",
       "45  [0.8925, 0.904842342342, 0.872466216216, 0.972...  \n",
       "30  [0.883611111111, 0.898367117117, 0.87528153153...  \n",
       "7   [0.893333333333, 0.894988738739, 0.87359234234...  \n",
       "32  [0.900555555556, 0.905405405405, 0.87105855855...  \n",
       "38  [0.893333333333, 0.896959459459, 0.875, 0.9690...  \n",
       "18  [0.900555555556, 0.897240990991, 0.86711711711...  \n",
       "6   [0.899444444444, 0.891047297297, 0.86965090090...  \n",
       "16  [0.897222222222, 0.890765765766, 0.87162162162...  \n",
       "35  [0.8925, 0.893581081081, 0.875844594595, 0.969...  \n",
       "46  [0.904166666667, 0.901182432432, 0.86486486486...  \n",
       "11  [0.879722222222, 0.894425675676, 0.86655405405...  \n",
       "3   [0.882777777778, 0.897804054054, 0.86120495495...  \n",
       "2   [0.883888888889, 0.899774774775, 0.86036036036...  \n",
       "5   [0.875, 0.894707207207, 0.857545045045, 0.9625...  \n",
       "4   [0.880833333333, 0.892454954955, 0.85726351351...  \n",
       "13  [0.887777777778, 0.891047297297, 0.86373873873...  \n",
       "0   [0.878611111111, 0.893581081081, 0.86007882882...  \n",
       "31  [0.873611111111, 0.899211711712, 0.85304054054...  \n",
       "44  [0.869166666667, 0.890202702703, 0.85472972973...  \n",
       "27  [0.861944444444, 0.888513513514, 0.84177927927...  \n",
       "42  [0.860555555556, 0.888513513514, 0.84712837837...  \n",
       "1   [0.829166666667, 0.884009009009, 0.84177927927...  \n",
       "19  [0.815555555556, 0.885416666667, 0.82573198198...  \n",
       "33  [0.761944444444, 0.868243243243, 0.81587837837...  \n",
       "10  [0.786944444444, 0.858952702703, 0.82291666666...  \n",
       "37  [0.756666666667, 0.868243243243, 0.81081081081...  \n",
       "36  [0.704444444444, 0.882601351351, 0.83727477477...  \n",
       "43  [0.743333333333, 0.786317567568, 0.79729729729...  \n",
       "24  [0.698611111111, 0.862612612613, 0.78125, 0.91...  \n",
       "21  [0.714444444444, 0.817004504505, 0.78941441441...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = pd.DataFrame(rand.grid_scores_).sort_values('mean_validation_score', ascending=False)\n",
    "grid.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912278292045\n",
      "{'n_estimators': 291, 'max_features': 411}\n"
     ]
    }
   ],
   "source": [
    "# look at best parameters\n",
    "\n",
    "print rand.best_score_\n",
    "print rand.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=450, max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit random forest with best parameters\n",
    "\n",
    "rfclass = RandomForestClassifier(n_estimators=800, max_features=450, oob_score=True)\n",
    "rfclass.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>363=PNGS</td>\n",
       "      <td>0.148488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>408=N</td>\n",
       "      <td>0.052014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>411=S</td>\n",
       "      <td>0.030612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>479=PNGS</td>\n",
       "      <td>0.028908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>482=W</td>\n",
       "      <td>0.024628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>466=G</td>\n",
       "      <td>0.016456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>481=T</td>\n",
       "      <td>0.014737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>411=PNGS</td>\n",
       "      <td>0.013893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>406=H</td>\n",
       "      <td>0.010319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>930=W</td>\n",
       "      <td>0.009623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "424   363=PNGS    0.148488\n",
       "488      408=N    0.052014\n",
       "494      411=S    0.030612\n",
       "627   479=PNGS    0.028908\n",
       "634      482=W    0.024628\n",
       "612      466=G    0.016456\n",
       "632      481=T    0.014737\n",
       "493   411=PNGS    0.013893\n",
       "485      406=H    0.010319\n",
       "1233     930=W    0.009623"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at feature importances\n",
    "\n",
    "forest_features_import = pd.DataFrame({'feature': X.columns, 'importance': rfclass.feature_importances_})\n",
    "forest_features_import.sort_values('importance', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up position in HXB2 for it's corresponding coordinate in the MSA\n",
    "\n",
    "reference = sequence_tokenizer(HXB2.seq)\n",
    "decoder = dict(enumerate(reference, start=1))\n",
    "decoder[392]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88571428571428568"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oob score\n",
    "\n",
    "rfclass.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fit Logistic Regression with best features\n",
    "\n",
    "    Evaluate with different iterations of selected features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define new df with selected features & perform train/test split\n",
    "\n",
    "selected_features = ['363=PNGS', '408=N', '411=S', '479=PNGS', '482=W']\n",
    "X = features_df[selected_features]\n",
    "y = neutdf.is_neutralized\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, \n",
    "                                                    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.1111298    2.59049643   0.99078487  11.07237876   1.29615324]]\n"
     ]
    }
   ],
   "source": [
    "# look at coefficients\n",
    "\n",
    "print logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.331746535146\n"
     ]
    }
   ],
   "source": [
    "# evaluate log loss\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_test)\n",
    "print metrics.log_loss(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.753706356528\n"
     ]
    }
   ],
   "source": [
    "# evaluate MCC\n",
    "\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print metrics.matthews_corrcoef(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do above with different feature combinations\n",
    "\n",
    "feature_selections = [['363=PNGS', '408=N', '411=S', '479=PNGS', '482=W'], ['363=PNGS', '408=N', '411=S', '479=PNGS'], \n",
    "                      ['363=PNGS', '408=N', '411=S'], ['363=PNGS', '408=N'], ['363=PNGS']]\n",
    "\n",
    "log_loss_scores = []\n",
    "MCC_scores = []\n",
    "\n",
    "for selection in feature_selections:\n",
    "    X = features_df[selection]\n",
    "    y = neutdf.is_neutralized\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, \n",
    "                                                    test_size=0.3)\n",
    "    logreg = LogisticRegression(C=1e9)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred_proba = logreg.predict_proba(X_test)\n",
    "    log_loss = metrics.log_loss(y_test, y_pred_proba)\n",
    "    y_pred_class = logreg.predict(X_test)\n",
    "    MCC = metrics.matthews_corrcoef(y_test, y_pred_class)\n",
    "    log_loss_scores.append(log_loss)\n",
    "    MCC_scores.append(MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCC</th>\n",
       "      <th>features</th>\n",
       "      <th>log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.664071</td>\n",
       "      <td>[363=PNGS, 408=N, 411=S, 479=PNGS]</td>\n",
       "      <td>0.334308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.651456</td>\n",
       "      <td>[363=PNGS, 408=N, 411=S, 479=PNGS, 482=W]</td>\n",
       "      <td>0.361570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.626258</td>\n",
       "      <td>[363=PNGS, 408=N, 411=S]</td>\n",
       "      <td>0.385761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.548702</td>\n",
       "      <td>[363=PNGS, 408=N]</td>\n",
       "      <td>0.416775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>[363=PNGS]</td>\n",
       "      <td>0.430039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MCC                                   features  log loss\n",
       "1  0.664071         [363=PNGS, 408=N, 411=S, 479=PNGS]  0.334308\n",
       "0  0.651456  [363=PNGS, 408=N, 411=S, 479=PNGS, 482=W]  0.361570\n",
       "2  0.626258                   [363=PNGS, 408=N, 411=S]  0.385761\n",
       "3  0.548702                          [363=PNGS, 408=N]  0.416775\n",
       "4  0.000000                                 [363=PNGS]  0.430039"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dataframe of the above\n",
    "\n",
    "log_reg_eval = pd.DataFrame({'features': feature_selections, 'log loss': log_loss_scores, 'MCC': MCC_scores})\n",
    "log_reg_eval.sort_values('MCC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
