{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Alphabet import generic_protein\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in neut data\n",
    "\n",
    "neut_file_path = '../data/VRC01_IC50_IC80.txt'\n",
    "\n",
    "neuts = pd.read_table(neut_file_path, header=0)\n",
    "neuts.rename(columns={'Virus name':'name', \n",
    "              'Subtype':'subtype',\n",
    "              'VRC01: IC50 geometric mean':'IC50',\n",
    "              'VRC01: IC80 geometric mean':'IC80'}, inplace=True)\n",
    "# neuts.set_index('name', inplace=True)\n",
    "neuts.drop(['Tier', 'Country', 'Accession', 'Alias', 'Seq data', \n",
    "            ' VRC01: IC50 by study', ' VRC01: IC80 by study', 'Unnamed: 11'], \n",
    "            axis=1, inplace=True)\n",
    "neuts = neuts[neuts.name != 'Geometric mean of detected']\n",
    "neuts = neuts[neuts.name != 'Geometric mean of all(undetected set to 100)'] \n",
    "neuts = neuts[neuts.name != '% detected (detected/total)'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in sequence data\n",
    "\n",
    "virus_name = []\n",
    "virus_seq = []\n",
    "passed_seqs = []\n",
    "\n",
    "fasta_file_path = '../data/VRC01 virus aa align.fasta'\n",
    "\n",
    "for seq_record in SeqIO.parse(fasta_file_path, 'fasta', \n",
    "                              alphabet=generic_protein):\n",
    "    try:\n",
    "        virus_name.append(seq_record.id.split('.')[2])\n",
    "        virus_seq.append(seq_record.seq)\n",
    "    except:\n",
    "        passed_seqs.append(seq_record)\n",
    "\n",
    "HXB2 = passed_seqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert sequence data to DataFrame\n",
    "\n",
    "seq_dict = {'sequence' : pd.Series(virus_seq, index=virus_name, \n",
    "                                   dtype='object')}\n",
    "seq_df = pd.DataFrame(seq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge neuts and seq_df\n",
    "\n",
    "neutdf = pd.merge(neuts, seq_df, how='inner', left_on='name', \n",
    "                    right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define neut categories\n",
    "\n",
    "def binarize_IC50(row):\n",
    "    if '>' in row.IC50:\n",
    "        return 0\n",
    "    else:\n",
    "        value = float(row.IC50)\n",
    "        return 0 if value > 50 else 1\n",
    "\n",
    "neutdf['is_neutralized'] = neutdf.apply(binarize_IC50, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>subtype</th>\n",
       "      <th>IC50</th>\n",
       "      <th>IC80</th>\n",
       "      <th>sequence</th>\n",
       "      <th>is_neutralized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013095_2_11</td>\n",
       "      <td>C</td>\n",
       "      <td>0.12352</td>\n",
       "      <td>0.46893</td>\n",
       "      <td>(M, R, V, K, G, -, I, L, R, N, Y, -, Q, Q, W, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001428_2_42</td>\n",
       "      <td>C</td>\n",
       "      <td>0.02057</td>\n",
       "      <td>0.06234</td>\n",
       "      <td>(M, R, V, R, G, -, I, L, R, N, Y, -, Q, Q, W, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0077_V1_C16</td>\n",
       "      <td>C</td>\n",
       "      <td>1.03134</td>\n",
       "      <td>1.79126</td>\n",
       "      <td>(M, R, V, M, G, -, S, M, R, N, C, -, Q, R, W, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00836_2_5</td>\n",
       "      <td>C</td>\n",
       "      <td>0.15389</td>\n",
       "      <td>0.78049</td>\n",
       "      <td>(M, R, V, R, G, -, I, R, R, N, Y, -, Q, H, W, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0260_V5_C36</td>\n",
       "      <td>A1</td>\n",
       "      <td>0.61196</td>\n",
       "      <td>1.70134</td>\n",
       "      <td>(M, R, V, M, G, -, I, Q, R, N, S, -, Q, C, F, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name subtype     IC50     IC80  \\\n",
       "0  0013095_2_11       C  0.12352  0.46893   \n",
       "1   001428_2_42       C  0.02057  0.06234   \n",
       "2   0077_V1_C16       C  1.03134  1.79126   \n",
       "3     00836_2_5       C  0.15389  0.78049   \n",
       "4   0260_V5_C36      A1  0.61196  1.70134   \n",
       "\n",
       "                                            sequence  is_neutralized  \n",
       "0  (M, R, V, K, G, -, I, L, R, N, Y, -, Q, Q, W, ...               1  \n",
       "1  (M, R, V, R, G, -, I, L, R, N, Y, -, Q, Q, W, ...               1  \n",
       "2  (M, R, V, M, G, -, S, M, R, N, C, -, Q, R, W, ...               1  \n",
       "3  (M, R, V, R, G, -, I, R, R, N, Y, -, Q, H, W, ...               1  \n",
       "4  (M, R, V, M, G, -, I, Q, R, N, S, -, Q, C, F, ...               1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "    Tokenize sequences w/ position value and amino acid identity\n",
    "    Tokenize PNGS sites with a regex\n",
    "    Vectorize tokens and create dataframe of dummy variables\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to tokenize sequence\n",
    "# input = sequence object, output = dictionary where index is position and\n",
    "# token is amino acid identity at that position\n",
    "\n",
    "amino_acids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', \n",
    "               'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "\n",
    "def sequence_tokenizer(seq):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    seq_list = list(str(seq).strip('*'))\n",
    "    working_peptide = list(enumerate(seq_list, start=1))\n",
    "    peptide_dict = {}\n",
    "    for index, amino in working_peptide:\n",
    "        if amino in amino_acids:\n",
    "            peptide_dict.update({index : amino})\n",
    "        else: \n",
    "            pass\n",
    "    return peptide_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to tokenize potential N-linked glycosylation sites \n",
    "# (PNGS) in sequence\n",
    "# input = sequence object, output = dictionary where index is position\n",
    "# and token = 'PNGS'\n",
    "\n",
    "def PNGS_tokenizer(seq):\n",
    "    seq_string = str(seq).strip('*')\n",
    "    PNGS_dict = {m.start(0)+1 : 'PNGS' \n",
    "                for m in re.finditer(r\"N[^P][ST]\", seq_string)}\n",
    "    return PNGS_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define feature extraction function where input = seq object and \n",
    "# output = one dictionary of all features\n",
    "\n",
    "def get_features(seq, use_positions=True, use_PNGS=True):\n",
    "    features = {}\n",
    "    if use_positions:\n",
    "        sequence_features = sequence_tokenizer(seq)\n",
    "        features.update(sequence_features)\n",
    "    if use_PNGS:\n",
    "        PNGS_features = PNGS_tokenizer(seq)\n",
    "        features.update(PNGS_features)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map get_features function to sequence column of neutdf\n",
    "\n",
    "neutdf['features_dict'] = neutdf.sequence.map(get_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>subtype</th>\n",
       "      <th>IC50</th>\n",
       "      <th>IC80</th>\n",
       "      <th>sequence</th>\n",
       "      <th>is_neutralized</th>\n",
       "      <th>features_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013095_2_11</td>\n",
       "      <td>C</td>\n",
       "      <td>0.12352</td>\n",
       "      <td>0.46893</td>\n",
       "      <td>(M, R, V, K, G, -, I, L, R, N, Y, -, Q, Q, W, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: u'M', 2: u'R', 3: u'V', 4: u'K', 5: u'G', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001428_2_42</td>\n",
       "      <td>C</td>\n",
       "      <td>0.02057</td>\n",
       "      <td>0.06234</td>\n",
       "      <td>(M, R, V, R, G, -, I, L, R, N, Y, -, Q, Q, W, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: u'M', 2: u'R', 3: u'V', 4: u'R', 5: u'G', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0077_V1_C16</td>\n",
       "      <td>C</td>\n",
       "      <td>1.03134</td>\n",
       "      <td>1.79126</td>\n",
       "      <td>(M, R, V, M, G, -, S, M, R, N, C, -, Q, R, W, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: u'M', 2: u'R', 3: u'V', 4: u'M', 5: u'G', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00836_2_5</td>\n",
       "      <td>C</td>\n",
       "      <td>0.15389</td>\n",
       "      <td>0.78049</td>\n",
       "      <td>(M, R, V, R, G, -, I, R, R, N, Y, -, Q, H, W, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: u'M', 2: u'R', 3: u'V', 4: u'R', 5: u'G', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0260_V5_C36</td>\n",
       "      <td>A1</td>\n",
       "      <td>0.61196</td>\n",
       "      <td>1.70134</td>\n",
       "      <td>(M, R, V, M, G, -, I, Q, R, N, S, -, Q, C, F, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: u'M', 2: u'R', 3: u'V', 4: u'M', 5: u'G', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name subtype     IC50     IC80  \\\n",
       "0  0013095_2_11       C  0.12352  0.46893   \n",
       "1   001428_2_42       C  0.02057  0.06234   \n",
       "2   0077_V1_C16       C  1.03134  1.79126   \n",
       "3     00836_2_5       C  0.15389  0.78049   \n",
       "4   0260_V5_C36      A1  0.61196  1.70134   \n",
       "\n",
       "                                            sequence  is_neutralized  \\\n",
       "0  (M, R, V, K, G, -, I, L, R, N, Y, -, Q, Q, W, ...               1   \n",
       "1  (M, R, V, R, G, -, I, L, R, N, Y, -, Q, Q, W, ...               1   \n",
       "2  (M, R, V, M, G, -, S, M, R, N, C, -, Q, R, W, ...               1   \n",
       "3  (M, R, V, R, G, -, I, R, R, N, Y, -, Q, H, W, ...               1   \n",
       "4  (M, R, V, M, G, -, I, Q, R, N, S, -, Q, C, F, ...               1   \n",
       "\n",
       "                                       features_dict  \n",
       "0  {1: u'M', 2: u'R', 3: u'V', 4: u'K', 5: u'G', ...  \n",
       "1  {1: u'M', 2: u'R', 3: u'V', 4: u'R', 5: u'G', ...  \n",
       "2  {1: u'M', 2: u'R', 3: u'V', 4: u'M', 5: u'G', ...  \n",
       "3  {1: u'M', 2: u'R', 3: u'V', 4: u'R', 5: u'G', ...  \n",
       "4  {1: u'M', 2: u'R', 3: u'V', 4: u'M', 5: u'G', ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000=F</th>\n",
       "      <th>1000=I</th>\n",
       "      <th>1000=L</th>\n",
       "      <th>1000=Q</th>\n",
       "      <th>1000=V</th>\n",
       "      <th>1001=Q</th>\n",
       "      <th>100=E</th>\n",
       "      <th>101=I</th>\n",
       "      <th>101=K</th>\n",
       "      <th>101=L</th>\n",
       "      <th>...</th>\n",
       "      <th>99=N</th>\n",
       "      <th>99=Q</th>\n",
       "      <th>99=R</th>\n",
       "      <th>99=Y</th>\n",
       "      <th>9=K</th>\n",
       "      <th>9=M</th>\n",
       "      <th>9=N</th>\n",
       "      <th>9=R</th>\n",
       "      <th>9=S</th>\n",
       "      <th>9=T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5920 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1000=F  1000=I  1000=L  1000=Q  1000=V  1001=Q  100=E  101=I  101=K  101=L  \\\n",
       "0       0       0       0       1       0       0      1      0      0      0   \n",
       "1       0       0       1       0       0       0      1      0      0      0   \n",
       "2       0       0       1       0       0       0      1      0      0      0   \n",
       "3       0       0       0       1       0       0      1      1      0      0   \n",
       "4       0       0       1       0       0       0      1      0      0      0   \n",
       "\n",
       "  ...   99=N  99=Q  99=R  99=Y  9=K  9=M  9=N  9=R  9=S  9=T  \n",
       "0 ...      0     1     0     0    0    0    0    1    0    0  \n",
       "1 ...      0     1     0     0    0    0    0    1    0    0  \n",
       "2 ...      0     1     0     0    0    0    0    1    0    0  \n",
       "3 ...      0     1     0     0    0    0    0    1    0    0  \n",
       "4 ...      0     1     0     0    0    0    0    1    0    0  \n",
       "\n",
       "[5 rows x 5920 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize data and build feature df\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "d_vect = DictVectorizer()\n",
    "\n",
    "list_features = list(neutdf.features_dict)\n",
    "sparse_features = d_vect.fit_transform(list_features)\n",
    "name_features = d_vect.get_feature_names()\n",
    "\n",
    "features_df = pd.DataFrame(sparse_features.toarray(), columns=name_features)\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up position in HXB2 for it's corresponding coordinate in the MSA\n",
    "\n",
    "reference = sequence_tokenizer(HXB2.seq)\n",
    "decoder = dict(enumerate(reference, start=1))\n",
    "decoder[456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['561=L', '561=M', '561=N', '561=R', '561=S', '561=V', '561=W', '561=Y']\n"
     ]
    }
   ],
   "source": [
    "# Examine features at positions 665 & 667 (MSA: 789 & 791)\n",
    "\n",
    "epitope_features = [col for col in features_df.columns if '561' in col]\n",
    "print epitope_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "    Trim down feature outliers (highly conserved sequences & single variants)\n",
    "    Other feature selection approaches (mRMR, incorporated methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_counts = np.sum(features_df, axis=0)/features_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x102bf9150>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEKCAYAAADTgGjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/X/VTGKDEpYjswAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x102b8d8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "% matplotlib inline\n",
    "\n",
    "feature_counts.plot.hist(title='Feature Frequencies', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to drop features that are shared by less than X% of sequences and/or more\n",
    "# than 1-X% of sequences\n",
    "\n",
    "def trim_feature_extremes(dataframe, percent_to_trim):\n",
    "    total_rows = dataframe.shape[0]\n",
    "    upper_threshold = (1 - percent_to_trim) * total_rows\n",
    "    lower_threshold = percent_to_trim * total_rows\n",
    "    column_filter_list = list((dataframe.sum(axis=0) >= lower_threshold) &\n",
    "                                (dataframe.sum(axis=0) < upper_threshold)) \n",
    "                                #True = keep, False = drop\n",
    "    column_filter_dict = zip(list(dataframe.columns), column_filter_list)\n",
    "    columns_to_keep = [column for column, keepornot in column_filter_dict \n",
    "                        if keepornot == True]\n",
    "    output_df = dataframe[columns_to_keep]\n",
    "    return output_df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359, 1405)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmed_features_df = trim_feature_extremes(features_df, 0.05)\n",
    "\n",
    "trimmed_features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Decision Tree Classifier\n",
    "\n",
    "    Use for feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define X & y as whole feature set without trimming features\n",
    "\n",
    "X = features_df\n",
    "y = neutdf.is_neutralized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63928571428571435, 0.60398056923918997, 0.60364668856048165, 0.64534482758620693, 0.63754789272030643, 0.67517651888341546, 0.65565681444991797, 0.65691570881226047, 0.65382868089764634, 0.68040640394088681, 0.65026546250684192, 0.6129406130268199, 0.66783524904214553, 0.6534674329501915, 0.65825670498084299, 0.65798850574712653, 0.68905582922824304, 0.66793103448275859, 0.72298850574712648, 0.65899835796387518, 0.68971264367816087, 0.67281609195402292, 0.69304597701149429, 0.69316912972085398, 0.66710180623973725, 0.67733169129720849, 0.70549261083743853, 0.64614942528735642, 0.65971264367816096, 0.69626436781609202, 0.65888341543513951, 0.66471264367816085, 0.69632183908045975, 0.69298850574712645, 0.70738916256157647, 0.67471264367816108, 0.66793103448275848, 0.66126436781609199, 0.6779310344827586, 0.65804597701149425, 0.68394088669950748, 0.67399835796387531, 0.68143678160919552, 0.68227422003284066, 0.6773316912972086, 0.68465517241379303, 0.65626436781609199, 0.68060755336617396, 0.66965517241379313, 0.69394088669950738, 0.66566502463054189, 0.66221674876847292, 0.65132183908045982, 0.64388341543513961, 0.68304597701149428, 0.70310344827586202, 0.71049261083743842, 0.68132183908045973, 0.65948275862068972, 0.65454022988505756, 0.67238916256157633, 0.66298850574712653, 0.67798850574712632, 0.67298850574712643, 0.64477011494252867, 0.66233169129720859, 0.66882594417077179, 0.68399835796387531, 0.68143678160919541, 0.66459770114942529, 0.66614942528735632, 0.66971264367816086, 0.66620689655172416, 0.68060755336617418, 0.67132183908045984, 0.65298850574712652, 0.67465517241379303, 0.66227422003284075, 0.65632183908045971, 0.70477011494252884, 0.67798850574712632, 0.6645977011494254, 0.70298850574712657, 0.65810344827586209, 0.70227422003284079, 0.66954022988505746, 0.67310344827586222, 0.66637931034482756, 0.67388341543513963, 0.66555008210180633, 0.6747701149425287, 0.66132183908045972, 0.7106075533661742, 0.67298850574712654, 0.65804597701149437, 0.66394088669950746, 0.69233169129720862, 0.67793103448275871, 0.69221674876847294, 0.66060755336617405]\n"
     ]
    }
   ],
   "source": [
    "# calculate best depth using roc_auc score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_depth_range = range(1, 101)\n",
    "\n",
    "roc_auc_scores = []\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "for depth in max_depth_range:\n",
    "    treeclass = DecisionTreeClassifier(max_depth=depth)\n",
    "    score = cross_val_score(treeclass, X, y, scoring='roc_auc', cv=10)\n",
    "    roc_auc_scores.append(np.mean(score))\n",
    "    \n",
    "print roc_auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGDCAYAAAAmkGrdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x102bf90d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graph roc_auc_scores vs max depth\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(max_depth_range, roc_auc_scores)\n",
    "plt.xlabel('max depth')\n",
    "plt.ylabel('roc auc score')\n",
    "\n",
    "plt.rcdefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.72298850574712648, 19)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(roc_auc_scores, max_depth_range), reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=20,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit tree using max depth of 3\n",
    "\n",
    "treeclass = DecisionTreeClassifier(max_depth=20)\n",
    "treeclass.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>561=R</td>\n",
       "      <td>0.283252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904</th>\n",
       "      <td>592=I</td>\n",
       "      <td>0.083387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>372=S</td>\n",
       "      <td>0.081425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>171=A</td>\n",
       "      <td>0.068659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>211=R</td>\n",
       "      <td>0.067711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4540</th>\n",
       "      <td>755=D</td>\n",
       "      <td>0.047022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>187=Y</td>\n",
       "      <td>0.037919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>633=D</td>\n",
       "      <td>0.036646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>43=G</td>\n",
       "      <td>0.036161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4846</th>\n",
       "      <td>808=F</td>\n",
       "      <td>0.035685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  importance\n",
       "3652   561=R    0.283252\n",
       "3904   592=I    0.083387\n",
       "1973   372=S    0.081425\n",
       "627    171=A    0.068659\n",
       "1012   211=R    0.067711\n",
       "4540   755=D    0.047022\n",
       "804    187=Y    0.037919\n",
       "4076   633=D    0.036646\n",
       "2542    43=G    0.036161\n",
       "4846   808=F    0.035685"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get feature importances\n",
    "\n",
    "feat_import = pd.DataFrame({'feature': features_df.columns, 'importance': treeclass.feature_importances_})\n",
    "feat_import.sort_values('importance', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up position in HXB2 for it's corresponding coordinate in the MSA\n",
    "\n",
    "reference = sequence_tokenizer(HXB2.seq)\n",
    "decoder = dict(enumerate(reference, start=1))\n",
    "decoder[471]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at other feature importances at same sites\n",
    "\n",
    "features_561 = [feat for feat in feat_import.feature if '561' in feat]\n",
    "features_592 = [feat for feat in feat_import.feature if '592' in feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>feature</th>\n",
       "      <th>561=L</th>\n",
       "      <th>561=M</th>\n",
       "      <th>561=N</th>\n",
       "      <th>561=R</th>\n",
       "      <th>561=S</th>\n",
       "      <th>561=V</th>\n",
       "      <th>561=W</th>\n",
       "      <th>561=Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>importance</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "feature     561=L  561=M  561=N     561=R  561=S  561=V  561=W  561=Y\n",
       "importance      0      0      0  0.283252      0      0      0      0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_import.set_index('feature', inplace=True)\n",
    "import_feat = feat_import.transpose()\n",
    "import_feat[features_561]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>feature</th>\n",
       "      <th>592=A</th>\n",
       "      <th>592=E</th>\n",
       "      <th>592=G</th>\n",
       "      <th>592=I</th>\n",
       "      <th>592=L</th>\n",
       "      <th>592=Q</th>\n",
       "      <th>592=S</th>\n",
       "      <th>592=T</th>\n",
       "      <th>592=V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>importance</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083387</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "feature     592=A  592=E  592=G     592=I  592=L  592=Q  592=S  592=T  592=V\n",
       "importance      0      0      0  0.083387      0      0      0      0      0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_feat[features_592]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Random Forest\n",
    "    \n",
    "    Use randomized grid search CV for n_estimators, max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import random forest classifier & define X & y using trimmed dataframe\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfclass = RandomForestClassifier()\n",
    "\n",
    "X = trimmed_features_df\n",
    "y = neutdf.is_neutralized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "estimators_range = range(0, 1501, 10)\n",
    "feature_range = range(0, 501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params={}, iid=True, n_iter=50, n_jobs=1,\n",
       "          param_distributions={'max_features': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, ...40, 1350, 1360, 1370, 1380, 1390, 1400, 1410, 1420, 1430, 1440, 1450, 1460, 1470, 1480, 1490, 1500]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist = dict(n_estimators=estimators_range, max_features=feature_range)\n",
    "rand = RandomizedSearchCV(rfclass, param_dist, n_iter=50, scoring='roc_auc', cv=5)\n",
    "rand.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>mean_validation_score</th>\n",
       "      <th>cv_validation_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{u'n_estimators': 150, u'max_features': 208}</td>\n",
       "      <td>0.801705</td>\n",
       "      <td>[0.798076923077, 0.794444444444, 0.65625, 0.80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{u'n_estimators': 160, u'max_features': 52}</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>[0.848717948718, 0.78125, 0.565972222222, 0.81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{u'n_estimators': 50, u'max_features': 394}</td>\n",
       "      <td>0.793464</td>\n",
       "      <td>[0.75641025641, 0.754861111111, 0.780555555556...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{u'n_estimators': 880, u'max_features': 180}</td>\n",
       "      <td>0.793185</td>\n",
       "      <td>[0.8, 0.774305555556, 0.627777777778, 0.817796...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>{u'n_estimators': 270, u'max_features': 236}</td>\n",
       "      <td>0.792950</td>\n",
       "      <td>[0.765384615385, 0.788194444444, 0.68402777777...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>{u'n_estimators': 560, u'max_features': 213}</td>\n",
       "      <td>0.791573</td>\n",
       "      <td>[0.814743589744, 0.790277777778, 0.6125, 0.800...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{u'n_estimators': 630, u'max_features': 61}</td>\n",
       "      <td>0.789918</td>\n",
       "      <td>[0.833974358974, 0.792361111111, 0.57361111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{u'n_estimators': 1330, u'max_features': 107}</td>\n",
       "      <td>0.788725</td>\n",
       "      <td>[0.789743589744, 0.793055555556, 0.60833333333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{u'n_estimators': 520, u'max_features': 233}</td>\n",
       "      <td>0.787577</td>\n",
       "      <td>[0.760897435897, 0.786805555556, 0.67013888888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>{u'n_estimators': 1270, u'max_features': 265}</td>\n",
       "      <td>0.787114</td>\n",
       "      <td>[0.765384615385, 0.788888888889, 0.62916666666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{u'n_estimators': 1030, u'max_features': 211}</td>\n",
       "      <td>0.786213</td>\n",
       "      <td>[0.760897435897, 0.775694444444, 0.62222222222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>{u'n_estimators': 780, u'max_features': 358}</td>\n",
       "      <td>0.785862</td>\n",
       "      <td>[0.765384615385, 0.777777777778, 0.63125, 0.80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{u'n_estimators': 1240, u'max_features': 65}</td>\n",
       "      <td>0.784635</td>\n",
       "      <td>[0.783974358974, 0.784027777778, 0.58819444444...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{u'n_estimators': 640, u'max_features': 210}</td>\n",
       "      <td>0.784127</td>\n",
       "      <td>[0.769871794872, 0.769444444444, 0.62986111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{u'n_estimators': 1490, u'max_features': 23}</td>\n",
       "      <td>0.783779</td>\n",
       "      <td>[0.805769230769, 0.785416666667, 0.55208333333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{u'n_estimators': 1410, u'max_features': 297}</td>\n",
       "      <td>0.783659</td>\n",
       "      <td>[0.763461538462, 0.782638888889, 0.62083333333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{u'n_estimators': 1270, u'max_features': 36}</td>\n",
       "      <td>0.782484</td>\n",
       "      <td>[0.808974358974, 0.765277777778, 0.55694444444...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{u'n_estimators': 320, u'max_features': 417}</td>\n",
       "      <td>0.781749</td>\n",
       "      <td>[0.730128205128, 0.784027777778, 0.65486111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{u'n_estimators': 1360, u'max_features': 468}</td>\n",
       "      <td>0.781240</td>\n",
       "      <td>[0.785897435897, 0.767361111111, 0.63263888888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{u'n_estimators': 620, u'max_features': 465}</td>\n",
       "      <td>0.780998</td>\n",
       "      <td>[0.782051282051, 0.776388888889, 0.65555555555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>{u'n_estimators': 200, u'max_features': 284}</td>\n",
       "      <td>0.780608</td>\n",
       "      <td>[0.733333333333, 0.78125, 0.616666666667, 0.81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{u'n_estimators': 980, u'max_features': 390}</td>\n",
       "      <td>0.780535</td>\n",
       "      <td>[0.746794871795, 0.772222222222, 0.65694444444...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>{u'n_estimators': 1190, u'max_features': 341}</td>\n",
       "      <td>0.780479</td>\n",
       "      <td>[0.760897435897, 0.767361111111, 0.64513888888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{u'n_estimators': 510, u'max_features': 370}</td>\n",
       "      <td>0.779857</td>\n",
       "      <td>[0.746153846154, 0.777777777778, 0.63194444444...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>{u'n_estimators': 650, u'max_features': 338}</td>\n",
       "      <td>0.779849</td>\n",
       "      <td>[0.775641025641, 0.781944444444, 0.62361111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{u'n_estimators': 1210, u'max_features': 461}</td>\n",
       "      <td>0.779814</td>\n",
       "      <td>[0.76858974359, 0.769444444444, 0.632638888889...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{u'n_estimators': 1210, u'max_features': 424}</td>\n",
       "      <td>0.779544</td>\n",
       "      <td>[0.747435897436, 0.774305555556, 0.66041666666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{u'n_estimators': 1180, u'max_features': 215}</td>\n",
       "      <td>0.779026</td>\n",
       "      <td>[0.755769230769, 0.781944444444, 0.61458333333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{u'n_estimators': 1350, u'max_features': 230}</td>\n",
       "      <td>0.779005</td>\n",
       "      <td>[0.767307692308, 0.775, 0.609027777778, 0.8043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{u'n_estimators': 430, u'max_features': 131}</td>\n",
       "      <td>0.778427</td>\n",
       "      <td>[0.769230769231, 0.8, 0.569444444444, 0.812853...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{u'n_estimators': 710, u'max_features': 35}</td>\n",
       "      <td>0.777839</td>\n",
       "      <td>[0.78141025641, 0.776388888889, 0.577083333333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{u'n_estimators': 860, u'max_features': 306}</td>\n",
       "      <td>0.777542</td>\n",
       "      <td>[0.760897435897, 0.781944444444, 0.63680555555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{u'n_estimators': 1490, u'max_features': 297}</td>\n",
       "      <td>0.777525</td>\n",
       "      <td>[0.764102564103, 0.78125, 0.586111111111, 0.81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{u'n_estimators': 1200, u'max_features': 293}</td>\n",
       "      <td>0.777204</td>\n",
       "      <td>[0.746794871795, 0.779166666667, 0.61180555555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{u'n_estimators': 860, u'max_features': 426}</td>\n",
       "      <td>0.776459</td>\n",
       "      <td>[0.769230769231, 0.778472222222, 0.61319444444...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{u'n_estimators': 1390, u'max_features': 384}</td>\n",
       "      <td>0.776429</td>\n",
       "      <td>[0.741666666667, 0.779861111111, 0.63263888888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{u'n_estimators': 960, u'max_features': 318}</td>\n",
       "      <td>0.776395</td>\n",
       "      <td>[0.753846153846, 0.772916666667, 0.63263888888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{u'n_estimators': 610, u'max_features': 387}</td>\n",
       "      <td>0.775929</td>\n",
       "      <td>[0.717948717949, 0.777083333333, 0.64652777777...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{u'n_estimators': 340, u'max_features': 165}</td>\n",
       "      <td>0.774644</td>\n",
       "      <td>[0.769230769231, 0.764583333333, 0.62430555555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{u'n_estimators': 760, u'max_features': 168}</td>\n",
       "      <td>0.774179</td>\n",
       "      <td>[0.753205128205, 0.786111111111, 0.60277777777...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{u'n_estimators': 1100, u'max_features': 380}</td>\n",
       "      <td>0.773566</td>\n",
       "      <td>[0.75641025641, 0.770138888889, 0.632638888889...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{u'n_estimators': 1160, u'max_features': 269}</td>\n",
       "      <td>0.772729</td>\n",
       "      <td>[0.747435897436, 0.771527777778, 0.6125, 0.789...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{u'n_estimators': 310, u'max_features': 151}</td>\n",
       "      <td>0.771816</td>\n",
       "      <td>[0.735256410256, 0.780555555556, 0.55625, 0.82...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{u'n_estimators': 120, u'max_features': 296}</td>\n",
       "      <td>0.770119</td>\n",
       "      <td>[0.733333333333, 0.799305555556, 0.62361111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{u'n_estimators': 190, u'max_features': 28}</td>\n",
       "      <td>0.768636</td>\n",
       "      <td>[0.723076923077, 0.7875, 0.558333333333, 0.802...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{u'n_estimators': 880, u'max_features': 194}</td>\n",
       "      <td>0.767664</td>\n",
       "      <td>[0.732692307692, 0.770833333333, 0.56458333333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>{u'n_estimators': 710, u'max_features': 301}</td>\n",
       "      <td>0.766770</td>\n",
       "      <td>[0.735256410256, 0.760416666667, 0.60763888888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{u'n_estimators': 550, u'max_features': 376}</td>\n",
       "      <td>0.766366</td>\n",
       "      <td>[0.733333333333, 0.770833333333, 0.62083333333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{u'n_estimators': 970, u'max_features': 418}</td>\n",
       "      <td>0.759277</td>\n",
       "      <td>[0.741666666667, 0.780555555556, 0.58333333333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>{u'n_estimators': 20, u'max_features': 267}</td>\n",
       "      <td>0.716016</td>\n",
       "      <td>[0.587179487179, 0.655555555556, 0.66388888888...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       parameters  mean_validation_score  \\\n",
       "19   {u'n_estimators': 150, u'max_features': 208}               0.801705   \n",
       "0     {u'n_estimators': 160, u'max_features': 52}               0.800049   \n",
       "35    {u'n_estimators': 50, u'max_features': 394}               0.793464   \n",
       "44   {u'n_estimators': 880, u'max_features': 180}               0.793185   \n",
       "45   {u'n_estimators': 270, u'max_features': 236}               0.792950   \n",
       "49   {u'n_estimators': 560, u'max_features': 213}               0.791573   \n",
       "27    {u'n_estimators': 630, u'max_features': 61}               0.789918   \n",
       "26  {u'n_estimators': 1330, u'max_features': 107}               0.788725   \n",
       "5    {u'n_estimators': 520, u'max_features': 233}               0.787577   \n",
       "40  {u'n_estimators': 1270, u'max_features': 265}               0.787114   \n",
       "33  {u'n_estimators': 1030, u'max_features': 211}               0.786213   \n",
       "41   {u'n_estimators': 780, u'max_features': 358}               0.785862   \n",
       "6    {u'n_estimators': 1240, u'max_features': 65}               0.784635   \n",
       "21   {u'n_estimators': 640, u'max_features': 210}               0.784127   \n",
       "43   {u'n_estimators': 1490, u'max_features': 23}               0.783779   \n",
       "10  {u'n_estimators': 1410, u'max_features': 297}               0.783659   \n",
       "32   {u'n_estimators': 1270, u'max_features': 36}               0.782484   \n",
       "7    {u'n_estimators': 320, u'max_features': 417}               0.781749   \n",
       "29  {u'n_estimators': 1360, u'max_features': 468}               0.781240   \n",
       "4    {u'n_estimators': 620, u'max_features': 465}               0.780998   \n",
       "37   {u'n_estimators': 200, u'max_features': 284}               0.780608   \n",
       "2    {u'n_estimators': 980, u'max_features': 390}               0.780535   \n",
       "39  {u'n_estimators': 1190, u'max_features': 341}               0.780479   \n",
       "25   {u'n_estimators': 510, u'max_features': 370}               0.779857   \n",
       "42   {u'n_estimators': 650, u'max_features': 338}               0.779849   \n",
       "23  {u'n_estimators': 1210, u'max_features': 461}               0.779814   \n",
       "12  {u'n_estimators': 1210, u'max_features': 424}               0.779544   \n",
       "9   {u'n_estimators': 1180, u'max_features': 215}               0.779026   \n",
       "13  {u'n_estimators': 1350, u'max_features': 230}               0.779005   \n",
       "31   {u'n_estimators': 430, u'max_features': 131}               0.778427   \n",
       "38    {u'n_estimators': 710, u'max_features': 35}               0.777839   \n",
       "15   {u'n_estimators': 860, u'max_features': 306}               0.777542   \n",
       "3   {u'n_estimators': 1490, u'max_features': 297}               0.777525   \n",
       "8   {u'n_estimators': 1200, u'max_features': 293}               0.777204   \n",
       "28   {u'n_estimators': 860, u'max_features': 426}               0.776459   \n",
       "16  {u'n_estimators': 1390, u'max_features': 384}               0.776429   \n",
       "1    {u'n_estimators': 960, u'max_features': 318}               0.776395   \n",
       "14   {u'n_estimators': 610, u'max_features': 387}               0.775929   \n",
       "47   {u'n_estimators': 340, u'max_features': 165}               0.774644   \n",
       "18   {u'n_estimators': 760, u'max_features': 168}               0.774179   \n",
       "30  {u'n_estimators': 1100, u'max_features': 380}               0.773566   \n",
       "24  {u'n_estimators': 1160, u'max_features': 269}               0.772729   \n",
       "20   {u'n_estimators': 310, u'max_features': 151}               0.771816   \n",
       "34   {u'n_estimators': 120, u'max_features': 296}               0.770119   \n",
       "11    {u'n_estimators': 190, u'max_features': 28}               0.768636   \n",
       "17   {u'n_estimators': 880, u'max_features': 194}               0.767664   \n",
       "46   {u'n_estimators': 710, u'max_features': 301}               0.766770   \n",
       "36   {u'n_estimators': 550, u'max_features': 376}               0.766366   \n",
       "22   {u'n_estimators': 970, u'max_features': 418}               0.759277   \n",
       "48    {u'n_estimators': 20, u'max_features': 267}               0.716016   \n",
       "\n",
       "                                 cv_validation_scores  \n",
       "19  [0.798076923077, 0.794444444444, 0.65625, 0.80...  \n",
       "0   [0.848717948718, 0.78125, 0.565972222222, 0.81...  \n",
       "35  [0.75641025641, 0.754861111111, 0.780555555556...  \n",
       "44  [0.8, 0.774305555556, 0.627777777778, 0.817796...  \n",
       "45  [0.765384615385, 0.788194444444, 0.68402777777...  \n",
       "49  [0.814743589744, 0.790277777778, 0.6125, 0.800...  \n",
       "27  [0.833974358974, 0.792361111111, 0.57361111111...  \n",
       "26  [0.789743589744, 0.793055555556, 0.60833333333...  \n",
       "5   [0.760897435897, 0.786805555556, 0.67013888888...  \n",
       "40  [0.765384615385, 0.788888888889, 0.62916666666...  \n",
       "33  [0.760897435897, 0.775694444444, 0.62222222222...  \n",
       "41  [0.765384615385, 0.777777777778, 0.63125, 0.80...  \n",
       "6   [0.783974358974, 0.784027777778, 0.58819444444...  \n",
       "21  [0.769871794872, 0.769444444444, 0.62986111111...  \n",
       "43  [0.805769230769, 0.785416666667, 0.55208333333...  \n",
       "10  [0.763461538462, 0.782638888889, 0.62083333333...  \n",
       "32  [0.808974358974, 0.765277777778, 0.55694444444...  \n",
       "7   [0.730128205128, 0.784027777778, 0.65486111111...  \n",
       "29  [0.785897435897, 0.767361111111, 0.63263888888...  \n",
       "4   [0.782051282051, 0.776388888889, 0.65555555555...  \n",
       "37  [0.733333333333, 0.78125, 0.616666666667, 0.81...  \n",
       "2   [0.746794871795, 0.772222222222, 0.65694444444...  \n",
       "39  [0.760897435897, 0.767361111111, 0.64513888888...  \n",
       "25  [0.746153846154, 0.777777777778, 0.63194444444...  \n",
       "42  [0.775641025641, 0.781944444444, 0.62361111111...  \n",
       "23  [0.76858974359, 0.769444444444, 0.632638888889...  \n",
       "12  [0.747435897436, 0.774305555556, 0.66041666666...  \n",
       "9   [0.755769230769, 0.781944444444, 0.61458333333...  \n",
       "13  [0.767307692308, 0.775, 0.609027777778, 0.8043...  \n",
       "31  [0.769230769231, 0.8, 0.569444444444, 0.812853...  \n",
       "38  [0.78141025641, 0.776388888889, 0.577083333333...  \n",
       "15  [0.760897435897, 0.781944444444, 0.63680555555...  \n",
       "3   [0.764102564103, 0.78125, 0.586111111111, 0.81...  \n",
       "8   [0.746794871795, 0.779166666667, 0.61180555555...  \n",
       "28  [0.769230769231, 0.778472222222, 0.61319444444...  \n",
       "16  [0.741666666667, 0.779861111111, 0.63263888888...  \n",
       "1   [0.753846153846, 0.772916666667, 0.63263888888...  \n",
       "14  [0.717948717949, 0.777083333333, 0.64652777777...  \n",
       "47  [0.769230769231, 0.764583333333, 0.62430555555...  \n",
       "18  [0.753205128205, 0.786111111111, 0.60277777777...  \n",
       "30  [0.75641025641, 0.770138888889, 0.632638888889...  \n",
       "24  [0.747435897436, 0.771527777778, 0.6125, 0.789...  \n",
       "20  [0.735256410256, 0.780555555556, 0.55625, 0.82...  \n",
       "34  [0.733333333333, 0.799305555556, 0.62361111111...  \n",
       "11  [0.723076923077, 0.7875, 0.558333333333, 0.802...  \n",
       "17  [0.732692307692, 0.770833333333, 0.56458333333...  \n",
       "46  [0.735256410256, 0.760416666667, 0.60763888888...  \n",
       "36  [0.733333333333, 0.770833333333, 0.62083333333...  \n",
       "22  [0.741666666667, 0.780555555556, 0.58333333333...  \n",
       "48  [0.587179487179, 0.655555555556, 0.66388888888...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = pd.DataFrame(rand.grid_scores_).sort_values('mean_validation_score', ascending=False)\n",
    "grid.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.801704781378\n",
      "{'n_estimators': 150, 'max_features': 208}\n"
     ]
    }
   ],
   "source": [
    "# look at best parameters\n",
    "\n",
    "print rand.best_score_\n",
    "print rand.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=200, max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit random forest with best parameters\n",
    "\n",
    "rfclass = RandomForestClassifier(n_estimators=150, max_features=200, oob_score=True)\n",
    "rfclass.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>561=R</td>\n",
       "      <td>0.050728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>564=G</td>\n",
       "      <td>0.047863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>587=E</td>\n",
       "      <td>0.032295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>359=N</td>\n",
       "      <td>0.016520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>717=Q</td>\n",
       "      <td>0.012739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>436=R</td>\n",
       "      <td>0.010606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>222=L</td>\n",
       "      <td>0.010562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>462=H</td>\n",
       "      <td>0.009628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>858=S</td>\n",
       "      <td>0.008681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>774=T</td>\n",
       "      <td>0.008164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  importance\n",
       "828    561=R    0.050728\n",
       "829    564=G    0.047863\n",
       "868    587=E    0.032295\n",
       "413    359=N    0.016520\n",
       "969    717=Q    0.012739\n",
       "572    436=R    0.010606\n",
       "248    222=L    0.010562\n",
       "620    462=H    0.009628\n",
       "1157   858=S    0.008681\n",
       "1032   774=T    0.008164"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at feature importances\n",
    "\n",
    "forest_features_import = pd.DataFrame({'feature': X.columns, 'importance': rfclass.feature_importances_})\n",
    "forest_features_import.sort_values('importance', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up position in HXB2 for it's corresponding coordinate in the MSA\n",
    "\n",
    "reference = sequence_tokenizer(HXB2.seq)\n",
    "decoder = dict(enumerate(reference, start=1))\n",
    "decoder[280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83561643835616439"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oob score\n",
    "\n",
    "rfclass.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fit Logistic Regression with best features\n",
    "\n",
    "    Evaluate with different iterations of selected features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define new df with selected features & perform train/test split\n",
    "\n",
    "selected_features = ['561=R', '564=G', '587=E', '359=N', '717=Q', '436=R', '222=L', '462=H']\n",
    "X = features_df[selected_features]\n",
    "y = neutdf.is_neutralized\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, \n",
    "                                                    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.09087358  3.39156162  1.22495903  2.24117383 -1.55514653 -0.32399965\n",
      "   1.63906945 -2.64579423]]\n"
     ]
    }
   ],
   "source": [
    "# look at coefficients\n",
    "\n",
    "print logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.337389282823\n"
     ]
    }
   ],
   "source": [
    "# evaluate log loss\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_test)\n",
    "print metrics.log_loss(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.632455532034\n"
     ]
    }
   ],
   "source": [
    "# evaluate MCC\n",
    "\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print metrics.matthews_corrcoef(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do above with different feature combinations\n",
    "\n",
    "feature_selections = [['561=R', '564=G', '587=E', '359=N', '717=Q', '436=R', '222=L', '462=H'], \n",
    "                      ['561=R', '564=G', '587=E', '359=N', '717=Q', '436=R', '222=L'], \n",
    "                      ['561=R', '564=G', '587=E', '359=N', '717=Q', '436=R'], \n",
    "                      ['561=R', '564=G', '587=E', '359=N', '717=Q'], ['561=R', '564=G', '587=E', '359=N'], \n",
    "                      ['561=R', '564=G', '587=E'], ['561=R', '564=G'], ['561=R']]\n",
    "\n",
    "log_loss_scores = []\n",
    "MCC_scores = []\n",
    "\n",
    "for selection in feature_selections:\n",
    "    X = features_df[selection]\n",
    "    y = neutdf.is_neutralized\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, \n",
    "                                                    test_size=0.3)\n",
    "    logreg = LogisticRegression(C=1e9)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred_proba = logreg.predict_proba(X_test)\n",
    "    log_loss = metrics.log_loss(y_test, y_pred_proba)\n",
    "    y_pred_class = logreg.predict(X_test)\n",
    "    MCC = metrics.matthews_corrcoef(y_test, y_pred_class)\n",
    "    log_loss_scores.append(log_loss)\n",
    "    MCC_scores.append(MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCC</th>\n",
       "      <th>features</th>\n",
       "      <th>log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.670855</td>\n",
       "      <td>[561=R, 564=G, 587=E, 359=N, 717=Q, 436=R, 222...</td>\n",
       "      <td>0.265706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.588672</td>\n",
       "      <td>[561=R]</td>\n",
       "      <td>0.335701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.584307</td>\n",
       "      <td>[561=R, 564=G, 587=E, 359=N, 717=Q]</td>\n",
       "      <td>0.329674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.553399</td>\n",
       "      <td>[561=R, 564=G]</td>\n",
       "      <td>0.326327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.542857</td>\n",
       "      <td>[561=R, 564=G, 587=E, 359=N, 717=Q, 436=R, 222=L]</td>\n",
       "      <td>0.336885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.506564</td>\n",
       "      <td>[561=R, 564=G, 587=E, 359=N]</td>\n",
       "      <td>0.304261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.457143</td>\n",
       "      <td>[561=R, 564=G, 587=E]</td>\n",
       "      <td>0.343071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.442719</td>\n",
       "      <td>[561=R, 564=G, 587=E, 359=N, 717=Q, 436=R]</td>\n",
       "      <td>0.482627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MCC                                           features  log loss\n",
       "0  0.670855  [561=R, 564=G, 587=E, 359=N, 717=Q, 436=R, 222...  0.265706\n",
       "7  0.588672                                            [561=R]  0.335701\n",
       "3  0.584307                [561=R, 564=G, 587=E, 359=N, 717=Q]  0.329674\n",
       "6  0.553399                                     [561=R, 564=G]  0.326327\n",
       "1  0.542857  [561=R, 564=G, 587=E, 359=N, 717=Q, 436=R, 222=L]  0.336885\n",
       "4  0.506564                       [561=R, 564=G, 587=E, 359=N]  0.304261\n",
       "5  0.457143                              [561=R, 564=G, 587=E]  0.343071\n",
       "2  0.442719         [561=R, 564=G, 587=E, 359=N, 717=Q, 436=R]  0.482627"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dataframe of the above\n",
    "\n",
    "log_reg_eval = pd.DataFrame({'features': feature_selections, 'log loss': log_loss_scores, 'MCC': MCC_scores})\n",
    "log_reg_eval.sort_values('MCC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
